{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 驾驶员状态检测\n",
    "\n",
    "根据汽车安全部门的调查显示，五分之一的交通事故都是由于驾驶员分心(distracted)造成的。每年，distracted driving会造成约42500人受伤，3000人死亡。这个数字非常惊人。\n",
    "\n",
    "[State Farm](https://www.statefarm.com/)希望通过车载的dashboard cameras来检测用户是否处于distracted driving的状态，从而发出警告。\n",
    "\n",
    "</br>\n",
    "<font color=red size=3 face=“黑体”>这是我实际的开发过程，我不会上来就写出最优的解决方案，而是把我所遇到的“坑”都给写出来，这些“坑”真的很经典</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 数据集获取\n",
    "\n",
    "[数据集](https://www.kaggle.com/c/state-farm-distracted-driver-detection/data)来自于kaggle，总共有三个文件需要下载，如下所示。其中imgs.zip是通过摄像头来抓取的驾驶员的状态的标记数据集。该数据集的大小有4G。\n",
    "\n",
    "* imgs.zip - 所有训练/测试图片打包的zip文件<font color=red size=3 face=“黑体”>(你需要自行下载)</font>\n",
    "* sample_submission.csv - 提交kaggle时候的格式\n",
    "* driver_imgs_list.csv - 文件的信息，文件名对应的图像中的司机ID以及图像中司机的状态ID。\n",
    "\n",
    "现在解压imgs.zip来观察\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/matplotlib/__init__.py:1067: UserWarning: Duplicate key in file \"/home/ubuntu/.config/matplotlib/matplotlibrc\", line #2\n",
      "  (fname, cnt))\n",
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/matplotlib/__init__.py:1067: UserWarning: Duplicate key in file \"/home/ubuntu/.config/matplotlib/matplotlibrc\", line #3\n",
      "  (fname, cnt))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data is ready!\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input\n",
    "from keras.layers.core import Lambda\n",
    "from keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
    "from keras.models import Model\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from urllib.request import urlretrieve\n",
    "from os.path import isfile, isdir\n",
    "from tqdm import tqdm\n",
    "import zipfile\n",
    "import os\n",
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "zip_name = 'imgs.zip'\n",
    "train_dir_name = 'train'\n",
    "test_dir_name = 'test'\n",
    "\n",
    "resnet_50_model_save_name = 'model_resnet50.h5'\n",
    "inceptionv3_model_save_name = 'model_inceptionv3.h5'\n",
    "xception_model_save_name = 'model_xception.h5'\n",
    "\n",
    "## check if the train and  test data is exist\n",
    "if not isdir(train_dir_name) or not isdir(test_dir_name):\n",
    "    if not isfile(zip_name):\n",
    "        print (\"Please download imgs.zip from kaggle!\")\n",
    "        assert(False)\n",
    "    else:\n",
    "        with zipfile.ZipFile(zip_name) as azip:\n",
    "            print (\"Now to extract %s \" % (zip_name))\n",
    "            azip.extractall()\n",
    "print (\"Data is ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们将检测驾驶员10种驾驶员的驾驶状态，如下\n",
    "\n",
    "* c0: 安全驾驶\n",
    "* c1: 右手打字\n",
    "* c2: 右手打电话\n",
    "* c3: 左手打字\n",
    "* c4: 左手打电话\n",
    "* c5: 调收音机\n",
    "* c6: 喝饮料\n",
    "* c7: 拿后面的东西\n",
    "* c8: 整理头发和化妆\n",
    "* c9: 和其他乘客说话\n",
    "\n",
    "其中，关于每一种驾驶状态的图片都分开存放，也就是有c0-c9文件夹存放各自状态的图片。此时文件夹的目录结构大概如下\n",
    "\n",
    "|----imgs.zip  \n",
    "|----train  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;|-----c0  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;|-----c1  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;|-----c2  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;|-----c3  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;|-----c4  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;|-----c5  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;|-----c6  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;|-----c7  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;|-----c8  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;|-----c9  \n",
    "|----test  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 数据集基本信息\n",
    "\n",
    "接下来就是了解数据集的基本信息：\n",
    "\n",
    "1. 统计训练测试样本数量\n",
    "2. 每一类训练数据的数量分布\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test file numbers:  79726\n",
      "Train file numbers:  22424\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "## get train and file nums\n",
    "train_class_dir_names = os.listdir(train_dir_name)\n",
    "test_size = len(os.listdir(test_dir_name))\n",
    "\n",
    "train_size = 0\n",
    "train_class_size = {}\n",
    "\n",
    "for dname in train_class_dir_names:\n",
    "    file_names = os.listdir(train_dir_name + '/' + dname)\n",
    "    train_class_size[dname] = len(file_names)\n",
    "    train_size = train_class_size[dname] + train_size\n",
    "    \n",
    "print (\"Test file numbers: \", test_size)\n",
    "print (\"Train file numbers: \", train_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "fig = plt.figure()  \n",
    "plt.bar(train_class_size.keys(), train_class_size.values(), 0.4, color=\"green\")  \n",
    "plt.xlabel(\"Classes\")  \n",
    "plt.ylabel(\"File nums\")  \n",
    "plt.title(\"Classes distribution\")  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "从上面的结果可以看出，我们总共有79726张测试图片，22424张测试图片。在训练图片中，每一个状态（类）包含大约2000张图片，分布还是比较均匀的。上面的可视化是根据状态来显示的，现在我们从另一个角度，看看每个司机大约包含了多少张图片。\n",
    "\n",
    "接下来就要解压文件driver_imgs_list.csv.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get driver_imgs_list_file\n",
    "driver_imgs_list_zip = 'driver_imgs_list.csv.zip'\n",
    "driver_imgs_list_file = 'driver_imgs_list.csv'\n",
    "\n",
    "if not isfile(driver_imgs_list_file):\n",
    "    if not isfile(driver_imgs_list_zip):\n",
    "        print (\"Please download river_imgs_list.csv.zip from kaggle!\")\n",
    "        assert(False)\n",
    "    else:\n",
    "        with zipfile.ZipFile(driver_imgs_list_zip) as azip:\n",
    "            print (\"Now to extract %s \" % (driver_imgs_list_zip))\n",
    "            azip.extractall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>classname</th>\n",
       "      <th>img</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>22424</td>\n",
       "      <td>22424</td>\n",
       "      <td>22424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>26</td>\n",
       "      <td>10</td>\n",
       "      <td>22424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>p021</td>\n",
       "      <td>c0</td>\n",
       "      <td>img_29427.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1237</td>\n",
       "      <td>2489</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       subject classname            img\n",
       "count    22424     22424          22424\n",
       "unique      26        10          22424\n",
       "top       p021        c0  img_29427.jpg\n",
       "freq      1237      2489              1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(driver_imgs_list_file)\n",
    "\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p021    1237\n",
      "p022    1233\n",
      "p024    1226\n",
      "p026    1196\n",
      "p016    1078\n",
      "p066    1034\n",
      "p049    1011\n",
      "p051     920\n",
      "p014     876\n",
      "p015     875\n",
      "p035     848\n",
      "p047     835\n",
      "p012     823\n",
      "p081     823\n",
      "p064     820\n",
      "p075     814\n",
      "p061     809\n",
      "p056     794\n",
      "p050     790\n",
      "p052     740\n",
      "p002     725\n",
      "p045     724\n",
      "p039     651\n",
      "p041     605\n",
      "p042     591\n",
      "p072     346\n",
      "Name: subject, dtype: int64\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2160x720 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ts = df['subject'].value_counts()\n",
    "print (ts)\n",
    "fig = plt.figure(figsize=(30,10))  \n",
    "plt.bar(ts.index.tolist(), ts.iloc[:].tolist(), 0.4, color=\"green\")  \n",
    "plt.xlabel(\"Driver ID\")  \n",
    "plt.ylabel(\"File nums\")  \n",
    "plt.title(\"Driver ID distribution\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看出，我们的训练集的数据来自于26个不同的司机的状态，每个司机都是都拥有不同状态的图片，其中346号司机拥有的图片数量最少，为346张。21号司机拥有的图片数量最多，为1237张。可以看出，如果按照司机ID来观察数据，数据分布并不均匀。但是这并不影响我们的训练，因为我们主要关心的是每一个状态所拥有的图片是否均匀，而不是每一个司机所拥有的图片是否均匀。接下来我们来简单可视化一下每一类的样本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "state_des = {'c0':'safe driving','c1':'texting - right hand','c2':'talking on the phone - right','c3':'texting - left hand',  \\\n",
    "             'c4':'talking on the phone - left hand','c5':'operating the radio','c6':'drinking','c7':'reaching behind','c8':'hair and makeup',  \\\n",
    "             'c9':'talking to passenger'};\n",
    "\n",
    "## class that you want to display\n",
    "c = 0\n",
    "\n",
    "## random choose the filenames of the class\n",
    "dis_dir = train_dir_name + '/c' + str(c)\n",
    "dis_filenames = os.listdir(dis_dir)\n",
    "\n",
    "dis_list = np.random.randint(len(dis_filenames), size=(6))\n",
    "dis_list = [dis_filenames[index] for index in dis_list]\n",
    "\n",
    "plt.figure(1, figsize=(13, 13))\n",
    "\n",
    "for i,filename in enumerate(dis_list):\n",
    "    image = cv2.imread(dis_dir +  '/' + str(filename))\n",
    "    image = cv2.cvtColor(image,cv2.COLOR_BGR2RGB)\n",
    "    ax1=plt.subplot(3,3,i+1)\n",
    "    plt.imshow(image)\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(state_des['c'+str(c)] + \"\\n\" + str(image.shape))\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.单模型的迁移学习\n",
    "\n",
    "在做过了几个kaggle项目之后，对计算机视觉类的项目有了一个大概的直觉，如果要采用当前流行的CNN模型来完成项目，那么总是可以尝试迁移学习的，因为对于CNN来说，一些图片的“底层信息”（直线，边缘，眼睛，耳朵，猫脸，狗脸）是可以共享的，所以我们就可以利用各大模型在大型计算机视觉数据集中学习到的通用的“知识”，将其迁移到我们的项目的学习中，从而帮助我们更好地提取通用的特征。并且\n",
    "\n",
    "* 如果我们只拥有少量的数据集，那么就可以只训练top layer（全连接层，输出层）的权重，不学习top layer以外的层的权重。如果数据集很少的情况下执意要对top layer以外的层进行训练，极有可能破坏预训练模型在庞大数据集中学习的知识，反而造成不好的效果。  \n",
    "* 如果我们拥有中等数量的数据集，那么我们可以开放少量的卷积层进行权重的fine-tune，而且为了避免大的权重的更新对以前学习到的知识造成破坏，建议采用小的learning rate。\n",
    "* 如果我们拥有庞大的数据集，并且项目拥有足够的时间来进行训练，那么此时依然可以采用迁移学习，但是这时候我们会开放比第二种情况更多的层，甚至所有的层\n",
    "\n",
    "之前我们已经对数据集进行了一些基本的了解，发现训练集的数量为2万多，所以我将我们现在的情况定位为第一种（毕竟2万多相对于百万级别的数据还是太少）。所以现在我打算在单模型上面进行迁移学习，<font color=red size=3 face=“黑体”> 并且只更新top layer的权重 </font>（为什么这里标记为红色，后面你就知道了）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 resnet-50的单模型迁移学习(Train top layer only)\n",
    "\n",
    "我第一个尝试的模型是在ILSVRC 2015比赛中获得了冠军resnet-50，该模型利用residual block，解决了当网络深度增加是所产生的Degradation问题，即准确率会先上升然后达到饱和，再持续增加深度则会导致准确率下降（注意哟，这是训练集的准确率哟，不是验证集哟，所以不是过拟合问题）。我相信50层神经网络能够轻松应付本项目，并且不用担心会出现Degradation问题，何乐而不为呢？废话不多说，加载预训练权重并开始调参过程吧！\n",
    "\n",
    "这里说明一下：我的电脑的显卡是Gtx 960，这个显卡用于训练小的神经网络还可以，但是用于训练resnet这种规模的网络就有点儿捉襟见肘了。所以我租用的亚马逊AWS云主机，p3.2 xlarge，其竞价实例的价格大约是1美元每小时，如果没有接触过AWS的可以通过这篇文章来学习[如何利用AWS来进行深度学习](https://zhuanlan.zhihu.com/p/33173963?utm_source=wechat_session&utm_medium=social)(不知不觉又给亚马逊打了一下广告)，还有，如果你想用AWS的话，你需要一把梯子（翻墙）。如果不想翻墙的话，阿里巴巴也有类似的云主机，只不过就是价格贵了点儿，自己衡量吧！"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上面说了，我只会训练top layer的权重，所以为了方便之后的调参过程，这里采用bottleneck feature的方式来减少重复的前向传播过程，也就是提取所有样本在top layer之前的输出结果(对于resnet，该输出结果的维度是1*1*2048，以后统一叫做特征向量)，将其保存起来，从而将其作为top layer的输入来达到加速调参的过程。也算是一种用空间换取时间的策略吧！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 224, 224, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 112, 112, 64) 9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bn_conv1 (BatchNormalization)   (None, 112, 112, 64) 256         conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 112, 112, 64) 0           bn_conv1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 55, 55, 64)   0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2a (Conv2D)         (None, 55, 55, 64)   4160        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2a (BatchNormalizati (None, 55, 55, 64)   256         res2a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 55, 55, 64)   0           bn2a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2b (Conv2D)         (None, 55, 55, 64)   36928       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2b (BatchNormalizati (None, 55, 55, 64)   256         res2a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 55, 55, 64)   0           bn2a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2c (Conv2D)         (None, 55, 55, 256)  16640       activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch1 (Conv2D)          (None, 55, 55, 256)  16640       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2c (BatchNormalizati (None, 55, 55, 256)  1024        res2a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch1 (BatchNormalizatio (None, 55, 55, 256)  1024        res2a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 55, 55, 256)  0           bn2a_branch2c[0][0]              \n",
      "                                                                 bn2a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 55, 55, 256)  0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2a (Conv2D)         (None, 55, 55, 64)   16448       activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2a (BatchNormalizati (None, 55, 55, 64)   256         res2b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 55, 55, 64)   0           bn2b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2b (Conv2D)         (None, 55, 55, 64)   36928       activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2b (BatchNormalizati (None, 55, 55, 64)   256         res2b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 55, 55, 64)   0           bn2b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2c (Conv2D)         (None, 55, 55, 256)  16640       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2c (BatchNormalizati (None, 55, 55, 256)  1024        res2b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 55, 55, 256)  0           bn2b_branch2c[0][0]              \n",
      "                                                                 activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 55, 55, 256)  0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2a (Conv2D)         (None, 55, 55, 64)   16448       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2a (BatchNormalizati (None, 55, 55, 64)   256         res2c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 55, 55, 64)   0           bn2c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2b (Conv2D)         (None, 55, 55, 64)   36928       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2b (BatchNormalizati (None, 55, 55, 64)   256         res2c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 55, 55, 64)   0           bn2c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2c (Conv2D)         (None, 55, 55, 256)  16640       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2c (BatchNormalizati (None, 55, 55, 256)  1024        res2c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 55, 55, 256)  0           bn2c_branch2c[0][0]              \n",
      "                                                                 activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 55, 55, 256)  0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2a (Conv2D)         (None, 28, 28, 128)  32896       activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 28, 28, 128)  0           bn3a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 28, 28, 128)  0           bn3a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch1 (Conv2D)          (None, 28, 28, 512)  131584      activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch1 (BatchNormalizatio (None, 28, 28, 512)  2048        res3a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 28, 28, 512)  0           bn3a_branch2c[0][0]              \n",
      "                                                                 bn3a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 28, 28, 512)  0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 28, 28, 128)  0           bn3b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 28, 28, 128)  0           bn3b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 28, 28, 512)  0           bn3b_branch2c[0][0]              \n",
      "                                                                 activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 28, 28, 512)  0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 28, 28, 128)  0           bn3c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 28, 28, 128)  0           bn3c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 28, 28, 512)  0           bn3c_branch2c[0][0]              \n",
      "                                                                 activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 28, 28, 512)  0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 28, 28, 128)  0           bn3d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 28, 28, 128)  0           bn3d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 28, 28, 512)  0           bn3d_branch2c[0][0]              \n",
      "                                                                 activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 28, 28, 512)  0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2a (Conv2D)         (None, 14, 14, 256)  131328      activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 14, 14, 256)  0           bn4a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 14, 14, 256)  0           bn4a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch1 (Conv2D)          (None, 14, 14, 1024) 525312      activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch1 (BatchNormalizatio (None, 14, 14, 1024) 4096        res4a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 14, 14, 1024) 0           bn4a_branch2c[0][0]              \n",
      "                                                                 bn4a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 14, 14, 1024) 0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 14, 14, 256)  0           bn4b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 14, 14, 256)  0           bn4b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 14, 14, 1024) 0           bn4b_branch2c[0][0]              \n",
      "                                                                 activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 14, 14, 1024) 0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 14, 14, 256)  0           bn4c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 14, 14, 256)  0           bn4c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 14, 14, 1024) 0           bn4c_branch2c[0][0]              \n",
      "                                                                 activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 14, 14, 1024) 0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 14, 14, 256)  0           bn4d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 14, 14, 256)  0           bn4d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 14, 14, 1024) 0           bn4d_branch2c[0][0]              \n",
      "                                                                 activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 14, 14, 1024) 0           add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 14, 14, 256)  0           bn4e_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 14, 14, 256)  0           bn4e_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4e_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 14, 14, 1024) 0           bn4e_branch2c[0][0]              \n",
      "                                                                 activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 14, 14, 1024) 0           add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 14, 14, 256)  0           bn4f_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 14, 14, 256)  0           bn4f_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4f_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 14, 14, 1024) 0           bn4f_branch2c[0][0]              \n",
      "                                                                 activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 14, 14, 1024) 0           add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2a (Conv2D)         (None, 7, 7, 512)    524800      activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 7, 7, 512)    0           bn5a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 7, 7, 512)    0           bn5a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch1 (Conv2D)          (None, 7, 7, 2048)   2099200     activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch1 (BatchNormalizatio (None, 7, 7, 2048)   8192        res5a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 7, 7, 2048)   0           bn5a_branch2c[0][0]              \n",
      "                                                                 bn5a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 7, 7, 2048)   0           add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 7, 7, 512)    0           bn5b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 7, 7, 512)    0           bn5b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 7, 7, 2048)   0           bn5b_branch2c[0][0]              \n",
      "                                                                 activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 7, 7, 2048)   0           add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 7, 7, 512)    0           bn5c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 7, 7, 512)    0           bn5c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_16 (Add)                    (None, 7, 7, 2048)   0           bn5c_branch2c[0][0]              \n",
      "                                                                 activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 7, 7, 2048)   0           add_16[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "avg_pool (AveragePooling2D)     (None, 1, 1, 2048)   0           activation_49[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 23,587,712\n",
      "Trainable params: 23,534,592\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "## load pretrained resnet\n",
    "from keras.applications import resnet50\n",
    "from keras.layers.core import Lambda\n",
    "from keras.layers import Input\n",
    "\n",
    "resNet_input_shape = (224,224,3)\n",
    "res_x = Input(shape=resNet_input_shape)\n",
    "res_x = Lambda(resnet50.preprocess_input)(res_x)\n",
    "res_model = resnet50.ResNet50(include_top=False, weights='imagenet', input_tensor=res_x, input_shape=resNet_input_shape)\n",
    "\n",
    "res_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们使用的在ImageNet上训练的resnet-50模型，并且，我们没有加载top layer，因为接下来是要提取bottleneck feature，无需top layer。从模型的打印信息可以知道，该模型的输出维度为1*1*2048，但是我要保存的是1维的特征向量，所以需要将其进行类似flatten的操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "out = GlobalAveragePooling2D()(res_model.output)\n",
    "res_vec_model = Model(inputs=res_model.input, outputs=out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在得到了提取bottleneck feature的模型之后，就可以开始着手提取特征了，考虑到之后也可能使用类似的操作来提取其他模型的bottleneck feature，所以我就写了一个函数（所以上面两个cell只是用来说明如何构建提取feature的模型的，真正使用的是下面这个函数）。该函数先构造一个提取bottleneck feature的模型，做的事情和上面两个cell一样。后面使用了image data generator的方式来来进行bottleneck feature提取，为什么采用这种方式呢？因为这种方式并不会一次性地把所有图片都加载到内存中，而是采用类似队列一样的边使用边加载的方式进行数据的读取，这样可以大大地减少内存的使用。我们可以来算一算，如果将所有的数据一次性加载到内存中会消耗多少的内存？假设一张图片的大小为224*224*3（resnet-50需要的大小），那么我们有22424张训练集（还没有包含庞大的测试集），加入我们以uint8的data type来加载数据，那么训练集所占用的内存大小就是224*224*3*22424 = 3375439872，达到了惊人的3GB。所以测试集将占用超过9GB，总共就是12GB。这还没开始训练呢，就占用了如此多的内存，即使我使用的AWS主机的Tesla v100显卡有16GB内存，但是考虑到之后留给训练的余量，还是不要以这种方式来加载数据了。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model_vector_catch(MODEL, image_size, vect_file_name, vec_dir, train_dir, test_dir, preprocessing=None):\n",
    "    \"\"\"\n",
    "        MODEL:the model to extract bottleneck features\n",
    "        image_size：MODEL input size(h, w, channels)\n",
    "        vect_file_name:file to save vector\n",
    "        preprocessing:whether or not need preprocessing\n",
    "    \"\"\"\n",
    "    if isfile(vec_dir + '/' + vect_file_name):\n",
    "        print (\"%s already OK!\" % (vect_file_name))\n",
    "        return\n",
    "    \n",
    "    input_tensor = Input(shape=(image_size[0], image_size[1], 3))\n",
    "    \n",
    "    if preprocessing:\n",
    "        ## check if need preprocessing\n",
    "        input_tensor = Lambda(preprocessing)(input_tensor)\n",
    "    \n",
    "    model_no_top = MODEL(include_top=False, weights='imagenet', input_tensor=input_tensor, input_shape=(image_size[0], image_size[1], 3))\n",
    "   \n",
    "    ## flatten the output shape and generate model\n",
    "    out = GlobalAveragePooling2D()(model_no_top.output)\n",
    "    new_model = Model(inputs=model_no_top.input, outputs=out)\n",
    "    \n",
    "    ## get iamge generator\n",
    "    gen = ImageDataGenerator()\n",
    "    test_gen = ImageDataGenerator()\n",
    "    \n",
    "    \"\"\"\n",
    "    classes = ['c0', 'c1', 'c2', 'c3', 'c4', 'c5', 'c6', 'c7', 'c8', 'c9', ] -- cat is 0, dog is 1, so we need write this\n",
    "    class_mode = None -- i will not use like 'fit_fitgenerator', so i do not need labels\n",
    "    shuffle = False -- it is unneccssary\n",
    "    batch_size = 64 \n",
    "    \"\"\"\n",
    "    class_list = ['c0', 'c1', 'c2', 'c3', 'c4', 'c5', 'c6', 'c7', 'c8', 'c9', ]\n",
    "    train_generator = gen.flow_from_directory(train_dir, image_size, color_mode='rgb', \\\n",
    "                                              classes=class_list, class_mode=None, shuffle=False, batch_size=64)\n",
    "    \n",
    "    #test_generator = test_gen.flow_from_directory(test_dir, image_size, color_mode='rgb', \\\n",
    "                                          #class_mode=None, shuffle=False, batch_size=64)\n",
    "   \n",
    "    \"\"\"\n",
    "    steps = None, by default, the steps = len(generator)\n",
    "    \"\"\"\n",
    "    train_vector = new_model.predict_generator(train_generator)\n",
    "    #test_vector = new_model.predict_generator(test_generator)\n",
    "    \n",
    "    with h5py.File(vec_dir + \"/\" + (vect_file_name), 'w') as f: \n",
    "        f.create_dataset('x_train', data=train_vector)\n",
    "        f.create_dataset(\"y_train\", data=train_generator.classes)\n",
    "        #f.create_dataset(\"test\", data=test_vector)\n",
    "    print (\"Model %s vector cached complete!\" % (vect_file_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vec_dir = 'vect'\n",
    "\n",
    "if not isdir(vec_dir):\n",
    "    os.mkdir(vec_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 22424 images belonging to 10 classes.\n",
      "Model resnet50_vect.h5 vector cached complete!\n"
     ]
    }
   ],
   "source": [
    "res_vect_file_name = 'resnet50_vect.h5'\n",
    "\n",
    "model_vector_catch(resnet50.ResNet50, resNet_input_shape[:2], res_vect_file_name, vec_dir, train_dir_name, test_dir_name, resnet50.preprocess_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在我们已经提取好了训练集（暂时不提取测试集的bottleneck feature，等我先验证了这种方法是否好用之后，再做测试集的bottleneck feature的提取，因为训练模型的时候用不到测试集，所以不着急提取）的bottleneck feature，下面就是搭建模型的top layer来进行训练了，那么top layer要怎么搭建呢？在原始的resnet-50中，只有一个含有1000个隐藏单元的输出层，所以这里我们参考resnet-50的设计，改成一个含有10个隐藏单元的输出层（因为我们的类别是10），激活函数是softmax。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "v = 10\n",
    "\n",
    "input_tensor = Input(shape=(2048,))\n",
    "x = Dropout(0.5)(input_tensor)\n",
    "x = Dense(driver_classes, activation='softmax', name='res_dense_1')(x)\n",
    "\n",
    "resnet50_model = Model(inputs=input_tensor, outputs=x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在训练模型之前，需要先把保存在文件中的bottleneck feature提取到内存中来，便于之后的fit。进一步地，因为我们之前保存的label是0-9的数字，现在我们要使用one-hot的方式来表示。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def convert_to_one_hot(Y, C):\n",
    "    Y = np.eye(C)[Y.reshape(-1)]\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "x_train = []\n",
    "y_train = []\n",
    "\n",
    "with h5py.File(vec_dir + '/' + res_vect_file_name, 'r') as f:\n",
    "    x_train = np.array(f['x_train'])\n",
    "    y_train = np.array(f['y_train'])\n",
    "    \n",
    "    #one-hot vector\n",
    "    y_train = convert_to_one_hot(y_train, driver_classes)\n",
    "    \n",
    "    x_train, y_train = shuffle(x_train, y_train, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=red size=3 face=“黑体”>注意上面的代码！！！这里有一个坑，是我之前项目中犯过的，导致我的模型无论如何都不收敛，而且还花了很长时间去调试。就是shuffle操作，一定要shuffle啊，如果你的数据是每一类单独存放在一起的，如果不shuffle的话，那么每一个batch的数据都将是同一类的数据，导致模型根本学不到东西，因为这个batch我学习到了这一类的特点，另一个batch我就要学习另一类完全不同的特点，从而抛弃之前学习的内容，导致这样的恶性循环，无法收敛。因为这个错误是之前犯的，所以现在也就没有必要再专门调试说明了。</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来的过程就是设置编译参数，然后调试了。这里optimizer采用Adam，参数为默认参数。batch_size采用64，epoch先运行10代看看情况，验证集划分为0.2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 17939 samples, validate on 4485 samples\n",
      "Epoch 1/30\n",
      "17939/17939 [==============================] - 5s 254us/step - loss: 1.2879 - acc: 0.5758 - val_loss: 0.4706 - val_acc: 0.8783\n",
      "Epoch 2/30\n",
      "17939/17939 [==============================] - 2s 98us/step - loss: 0.6077 - acc: 0.7996 - val_loss: 0.2997 - val_acc: 0.9298\n",
      "Epoch 3/30\n",
      "17939/17939 [==============================] - 2s 96us/step - loss: 0.4998 - acc: 0.8343 - val_loss: 0.2223 - val_acc: 0.9483\n",
      "Epoch 4/30\n",
      "17939/17939 [==============================] - 2s 94us/step - loss: 0.4569 - acc: 0.8463 - val_loss: 0.2140 - val_acc: 0.9452\n",
      "Epoch 5/30\n",
      "17939/17939 [==============================] - 2s 95us/step - loss: 0.4240 - acc: 0.8575 - val_loss: 0.2061 - val_acc: 0.9465\n",
      "Epoch 6/30\n",
      "17939/17939 [==============================] - 2s 94us/step - loss: 0.4089 - acc: 0.8653 - val_loss: 0.1641 - val_acc: 0.9550\n",
      "Epoch 7/30\n",
      "17939/17939 [==============================] - 2s 94us/step - loss: 0.3981 - acc: 0.8657 - val_loss: 0.1955 - val_acc: 0.9394\n",
      "Epoch 8/30\n",
      "17939/17939 [==============================] - 2s 95us/step - loss: 0.3967 - acc: 0.8688 - val_loss: 0.1512 - val_acc: 0.9574\n",
      "Epoch 9/30\n",
      "17939/17939 [==============================] - 2s 95us/step - loss: 0.3788 - acc: 0.8712 - val_loss: 0.1469 - val_acc: 0.9601\n",
      "Epoch 10/30\n",
      "17939/17939 [==============================] - 2s 96us/step - loss: 0.3852 - acc: 0.8723 - val_loss: 0.1646 - val_acc: 0.9518\n",
      "Epoch 11/30\n",
      "17939/17939 [==============================] - 2s 95us/step - loss: 0.3733 - acc: 0.8766 - val_loss: 0.1443 - val_acc: 0.9550\n",
      "Epoch 12/30\n",
      "17939/17939 [==============================] - 2s 95us/step - loss: 0.3858 - acc: 0.8735 - val_loss: 0.1474 - val_acc: 0.9603\n",
      "Epoch 13/30\n",
      "17939/17939 [==============================] - 2s 98us/step - loss: 0.3707 - acc: 0.8773 - val_loss: 0.1286 - val_acc: 0.9608\n",
      "Epoch 14/30\n",
      "17939/17939 [==============================] - 2s 97us/step - loss: 0.3597 - acc: 0.8810 - val_loss: 0.1340 - val_acc: 0.9581\n",
      "Epoch 15/30\n",
      "17939/17939 [==============================] - 2s 102us/step - loss: 0.3754 - acc: 0.8762 - val_loss: 0.2203 - val_acc: 0.9280\n",
      "Epoch 16/30\n",
      "17939/17939 [==============================] - 2s 99us/step - loss: 0.3603 - acc: 0.8821 - val_loss: 0.1307 - val_acc: 0.9628\n",
      "Epoch 17/30\n",
      "17939/17939 [==============================] - 2s 95us/step - loss: 0.3683 - acc: 0.8817 - val_loss: 0.1338 - val_acc: 0.9608\n",
      "Epoch 18/30\n",
      "17939/17939 [==============================] - 2s 95us/step - loss: 0.3640 - acc: 0.8819 - val_loss: 0.1180 - val_acc: 0.9654\n",
      "Epoch 19/30\n",
      "17939/17939 [==============================] - 2s 95us/step - loss: 0.3670 - acc: 0.8812 - val_loss: 0.1216 - val_acc: 0.9621\n",
      "Epoch 20/30\n",
      "17939/17939 [==============================] - 2s 95us/step - loss: 0.3505 - acc: 0.8855 - val_loss: 0.1128 - val_acc: 0.9672\n",
      "Epoch 21/30\n",
      "17939/17939 [==============================] - 2s 98us/step - loss: 0.3689 - acc: 0.8801 - val_loss: 0.1253 - val_acc: 0.9632\n",
      "Epoch 22/30\n",
      "17939/17939 [==============================] - 2s 95us/step - loss: 0.3670 - acc: 0.8808 - val_loss: 0.1418 - val_acc: 0.9538\n",
      "Epoch 23/30\n",
      "17939/17939 [==============================] - 2s 95us/step - loss: 0.3567 - acc: 0.8866 - val_loss: 0.1127 - val_acc: 0.9672\n",
      "Epoch 24/30\n",
      "17939/17939 [==============================] - 2s 96us/step - loss: 0.3484 - acc: 0.8870 - val_loss: 0.1269 - val_acc: 0.9614\n",
      "Epoch 25/30\n",
      "17939/17939 [==============================] - 2s 97us/step - loss: 0.3588 - acc: 0.8845 - val_loss: 0.1109 - val_acc: 0.9650\n",
      "Epoch 26/30\n",
      "17939/17939 [==============================] - 2s 95us/step - loss: 0.3672 - acc: 0.8822 - val_loss: 0.1100 - val_acc: 0.9666\n",
      "Epoch 27/30\n",
      "17939/17939 [==============================] - 2s 94us/step - loss: 0.3477 - acc: 0.8882 - val_loss: 0.1082 - val_acc: 0.9683\n",
      "Epoch 28/30\n",
      "17939/17939 [==============================] - 2s 96us/step - loss: 0.3647 - acc: 0.8839 - val_loss: 0.1119 - val_acc: 0.9686\n",
      "Epoch 29/30\n",
      "17939/17939 [==============================] - 2s 94us/step - loss: 0.3504 - acc: 0.8885 - val_loss: 0.1083 - val_acc: 0.9677\n",
      "Epoch 30/30\n",
      "17939/17939 [==============================] - 2s 96us/step - loss: 0.3562 - acc: 0.8877 - val_loss: 0.0988 - val_acc: 0.9706\n"
     ]
    }
   ],
   "source": [
    "resnet50_model.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "hist = resnet50_model.fit(x_train, y_train, batch_size=32, epochs=30, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我尝试过了很多优化算法，Adam，SGD等，包括设置了低的学习速率，以及学习速率衰减，但是现象都和上面的训练结果惊人的相似，主要现象分为两方面：\n",
    "\n",
    "* (训练集loss居高不下)训练集的loss一直在0.35左右摆动，无论如何也无法有效降低（参考kaggle排行榜上的前10名的loss，均小于0.13）\n",
    "* (验证集loss远远低于训练集loss)val_loss远远低于train_loss，经过30个epoch后，train_loss为0.35，而val_loss为0.09,并且val_loss还有继续下降的趋势。\n",
    "\n",
    "<font color=red size=3 face=“黑体”>大家记住，上面就是我遇到的两个最大的“坑”</font>\n",
    "\n",
    "下面我们就来一一分析这两个“坑”，并给出解决方案。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.1 针对“训练集loss高居不下”的现象\n",
    "\n",
    "先暂且不管模型的验证集的loss是如何如何低，如何如何完美。现在只关心训练集的loss，其值高达0.35，按照正常思维，这就是模型欠拟合了。一般解决欠拟合的套路如下：\n",
    "* 训练集loss反映了偏差(bias)的大小，bias反映了模型本的拟合能力，所以在模型拟合能力不够的情况下可以适当增加模型的复杂度，加入更多的隐藏层或者隐藏单元。  \n",
    "\n",
    "<font color=red size=3 face=“黑体”>结果：我尝试了在输出层之前中加入了两个含有1024个隐藏单元的全连接层（这里就不给出代码了，读者可以自行尝试），但是根本没效果</font>\n",
    "\n",
    "* 减小正则项，其实这也算是提高模型复杂度。对于本项目来说就是减小dropout的drop rate（等效于增大keep probability）  \n",
    "\n",
    "<font color=red size=3 face=“黑体”>结果：无效！</font>\n",
    "\n",
    "在上述两种方法都尝试失败了之后，说明正常的套路已经没有用了，是不是我的思考方向错误了呢？是否不应该单纯地从模型的角度分析问题？是否应该尝试转换思路？所以我就开始尝试从数据集本身开始分析。\n",
    "\n",
    "因为我们采用的策略是迁移学习，迁移学习的权重是来自于resnet-50在ImageNet上进行预训练的权重，也就是说我们靠这些ImageNet训练出来权重进行bottleneck feature的提取，但是结果大家都看到了，目前这样的方法并不能适用于我们的问题，那就是说提取的bottleneck feature不能帮助我们很好地进行学习，如果是这样的话，那就说明一个问题，我们的司机数据集和ImageNet数据集是有点儿“不一样”的。接下来我们就来分析分析这个不一样在哪里？\n",
    "\n",
    "1. 首先ImageNet数据集包含有1000种类别的图片，其中的数据大都是来自于不同的场景，拥有复杂的背景。但是我们的司机数据均来自于同一个场景（一个司机坐在车里，前面有一个方向盘），而且同一个司机的数据来自于同一个视频流，也就是说我们司机数据之间本身很相似！！！！\n",
    "\n",
    "那么预训练的resnet-50（不含有top layer）对非常相似的司机数据进行提取时，会发生什么呢？当然就是会提取出一些非常相似的bottleneck feature！！（猜想预训练模型会这么‘干’：‘我’提取出了这张图片的信息，这张图片有脸，有手，手方向盘。。。但是我们需要的似乎不仅仅是这些信息），也就是不同的司机状态的数据也会提取出非常相似的feature的话，那么对于司机问题来说，这些feature就是无用的feature（当然‘无用’说得太过分了，毕竟训练的模型也有88%的准确率呢！只是说提取的特征信息还不能够满足本项目的需求），当然也就不能获得很好的训练效果了。\n",
    "\n",
    "好了，原因知道了那么解决方法也就明朗了。解决方法就是开放更多地层，因为我们的模型需要学习更多的关于司机数据集的‘知识’。既然要开放更多的层，那么bottleneck feature的方法对于我们来说就不太使用了，因为模型中间的层一般维度都比较大，比如14*14*256，在20000个样本的情况下要占用4G的内存，如果再加上测试集的话，内存就消耗完了(而且如果AWS中选择K80显卡的话，只有11G的内存，根本不够)。所以现在我们就要对网络进行整体的训练。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 resnet-50的单模型迁移学习(train more convolution layers)\n",
    "\n",
    "接下来的大部分的操作和之前相似，不一样的是我们现在要开放更多的卷积层进行学习。在这之前，让我们先来准备用于训练的数据，这次我还是打算采用imagedataGenerator来产生训练的数据，同时用fitgenerator来进行训练。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "此时的验证集的数据需要单独地列出来（因为待会儿训练的时候我使用的是fit_generator，而这个接口是不支持validation_split参数的，所以需要手动地将验证集分出来），我决定和之前一样采用总样本数量的20%的样本进行训练，所以我需要在每一个类别中提取出20%的样本作为验证集。这里为了节约磁盘空间，我将采用软链接的形式来建立train_link数据集。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "link_path = 'train_link'\n",
    "link_train_path = 'train_link/train'\n",
    "link_valid_path = 'train_link/validation'\n",
    "\n",
    "test_link_path = 'test_link/data'\n",
    "\n",
    "classes = ['c0', 'c1', 'c2', 'c3', 'c4', 'c5', 'c6', 'c7', 'c8', 'c9']\n",
    "\n",
    "if not isdir(test_link_path):\n",
    "    os.makedirs(test_link_path)\n",
    "    c_filenames = os.listdir(test_dir_name)\n",
    "    \n",
    "    for file in c_filenames:\n",
    "        os.symlink('../../' + test_dir_name + '/' + file, test_link_path + '/' + file)\n",
    "\n",
    "if not isdir(link_path):\n",
    "    os.makedirs(link_train_path)\n",
    "    os.makedirs(link_valid_path)\n",
    "    \n",
    "    # make c0-c9\n",
    "    for c in classes:\n",
    "        os.makedirs(link_train_path + '/' + c)\n",
    "        os.makedirs(link_valid_path + '/' + c)\n",
    "        \n",
    "    # create link from train dir\n",
    "    for c in classes:\n",
    "        # get path name\n",
    "        c_path = train_dir_name + '/' + c\n",
    "        train_dst_path = link_train_path + '/' + c\n",
    "        valid_dst_path = link_valid_path + '/' + c\n",
    "        \n",
    "        # list all file name of this class\n",
    "        c_filenames = os.listdir(c_path)\n",
    "        valid_size = int (len(c_filenames)*0.2)\n",
    "        \n",
    "        # create validation data of this class\n",
    "        for file in c_filenames[:valid_size]:\n",
    "            os.symlink('../../../' + c_path + '/' + file, valid_dst_path + '/' + file)\n",
    "\n",
    "        # create train data of this class\n",
    "        for file in c_filenames[valid_size:]:\n",
    "            os.symlink('../../../' + c_path + '/' + file, train_dst_path + '/' + file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_generator(train_dir, valid_dir, test_dir, image_size): \n",
    "    gen = ImageDataGenerator()\n",
    "    gen_valid = ImageDataGenerator()\n",
    "    test_gen = ImageDataGenerator()\n",
    "    \n",
    "    \"\"\"\n",
    "    classes = ['c0', 'c1', 'c2', 'c3', 'c4', 'c5', 'c6', 'c7', 'c8', 'c9'] -- cat is 0, dog is 1, so we need write this\n",
    "    class_mode = categorical, the returned label mode\n",
    "    shuffle = True, we need, \n",
    "    batch_size = 64 \n",
    "    \"\"\"\n",
    "    class_list = ['c0', 'c1', 'c2', 'c3', 'c4', 'c5', 'c6', 'c7', 'c8', 'c9']\n",
    "    \n",
    "    # create train generator\n",
    "    train_generator = gen.flow_from_directory(train_dir, image_size, color_mode='rgb', \\\n",
    "                                              classes=class_list, class_mode='categorical', shuffle=True, batch_size=64)\n",
    "    \n",
    "    # create validation generator\n",
    "    valid_generator = gen_valid.flow_from_directory(valid_dir, image_size, color_mode='rgb', \\\n",
    "                                              classes=class_list, class_mode='categorical', shuffle=False, batch_size=64)\n",
    "    \n",
    "    test_generator = test_gen.flow_from_directory(test_dir, image_size, color_mode='rgb', \\\n",
    "                                          class_mode=None, shuffle=False, batch_size=64)\n",
    "    \n",
    "    return train_generator, valid_generator, test_generator\n",
    "#, test_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 17943 images belonging to 10 classes.\n",
      "Found 4481 images belonging to 10 classes.\n",
      "Found 0 images belonging to 0 classes.\n"
     ]
    }
   ],
   "source": [
    "resnet50_train_generator, resnet50_valid_generator, resnet50_test_generator = get_data_generator(link_train_path, link_valid_path, test_link_path, resNet_input_shape[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在数据准备好了，接下来就是搭建模型，冻结多数的层（根据layer的名字来冻结）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_built(MODEL, input_shape, preprocess_input, classes, last_frozen_layer_name):\n",
    "    \"\"\"\n",
    "        MODEL:                  pretrained model\n",
    "        input_shape:            pre-trained model's input shape\n",
    "        preprocessing_input:    pre-trained model's preprocessing function\n",
    "        last_frozen_layer_name: last layer to frozen  \n",
    "    \"\"\"\n",
    "    \n",
    "    ## get pretrained model\n",
    "    x = Input(shape=input_shape)\n",
    "    \n",
    "    if preprocess_input:\n",
    "        x = Lambda(preprocess_input)(x)\n",
    "    \n",
    "    notop_model = MODEL(include_top=False, weights='imagenet', input_tensor=x, input_shape=input_shape)\n",
    "    \n",
    "    x = GlobalAveragePooling2D()(notop_model.output)\n",
    "\n",
    "    ## build top layer\n",
    "    x = Dropout(0.5, name='dropout_1')(x)\n",
    "    out = Dense(classes, activation='softmax', name='dense_1')(x)\n",
    "    \n",
    "    ret_model = Model(inputs=notop_model.input, outputs=out)\n",
    "    \n",
    "    ## Frozen some layer\n",
    "    #for layer in ret_model.layers:\n",
    "        #layer.trainable = False\n",
    "        #if layer.name == last_frozen_layer_name:\n",
    "        #break\n",
    "    \n",
    "    return ret_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications import xception\n",
    "resnet50_model = model_built(resnet50.ResNet50, resNet_input_shape, resnet50.preprocess_input, 10, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, 224, 224, 3)  0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           lambda_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 112, 112, 64) 9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bn_conv1 (BatchNormalization)   (None, 112, 112, 64) 256         conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 112, 112, 64) 0           bn_conv1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 55, 55, 64)   0           activation_50[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2a (Conv2D)         (None, 55, 55, 64)   4160        max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2a (BatchNormalizati (None, 55, 55, 64)   256         res2a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, 55, 55, 64)   0           bn2a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2b (Conv2D)         (None, 55, 55, 64)   36928       activation_51[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2b (BatchNormalizati (None, 55, 55, 64)   256         res2a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, 55, 55, 64)   0           bn2a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2c (Conv2D)         (None, 55, 55, 256)  16640       activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch1 (Conv2D)          (None, 55, 55, 256)  16640       max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2c (BatchNormalizati (None, 55, 55, 256)  1024        res2a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch1 (BatchNormalizatio (None, 55, 55, 256)  1024        res2a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_17 (Add)                    (None, 55, 55, 256)  0           bn2a_branch2c[0][0]              \n",
      "                                                                 bn2a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, 55, 55, 256)  0           add_17[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2a (Conv2D)         (None, 55, 55, 64)   16448       activation_53[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2a (BatchNormalizati (None, 55, 55, 64)   256         res2b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, 55, 55, 64)   0           bn2b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2b (Conv2D)         (None, 55, 55, 64)   36928       activation_54[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2b (BatchNormalizati (None, 55, 55, 64)   256         res2b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, 55, 55, 64)   0           bn2b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2c (Conv2D)         (None, 55, 55, 256)  16640       activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2c (BatchNormalizati (None, 55, 55, 256)  1024        res2b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_18 (Add)                    (None, 55, 55, 256)  0           bn2b_branch2c[0][0]              \n",
      "                                                                 activation_53[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, 55, 55, 256)  0           add_18[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2a (Conv2D)         (None, 55, 55, 64)   16448       activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2a (BatchNormalizati (None, 55, 55, 64)   256         res2c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, 55, 55, 64)   0           bn2c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2b (Conv2D)         (None, 55, 55, 64)   36928       activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2b (BatchNormalizati (None, 55, 55, 64)   256         res2c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, 55, 55, 64)   0           bn2c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2c (Conv2D)         (None, 55, 55, 256)  16640       activation_58[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2c (BatchNormalizati (None, 55, 55, 256)  1024        res2c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_19 (Add)                    (None, 55, 55, 256)  0           bn2c_branch2c[0][0]              \n",
      "                                                                 activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, 55, 55, 256)  0           add_19[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2a (Conv2D)         (None, 28, 28, 128)  32896       activation_59[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, 28, 28, 128)  0           bn3a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_60[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, 28, 28, 128)  0           bn3a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_61[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch1 (Conv2D)          (None, 28, 28, 512)  131584      activation_59[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch1 (BatchNormalizatio (None, 28, 28, 512)  2048        res3a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_20 (Add)                    (None, 28, 28, 512)  0           bn3a_branch2c[0][0]              \n",
      "                                                                 bn3a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, 28, 28, 512)  0           add_20[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_62[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, 28, 28, 128)  0           bn3b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_63[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (None, 28, 28, 128)  0           bn3b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_64[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_21 (Add)                    (None, 28, 28, 512)  0           bn3b_branch2c[0][0]              \n",
      "                                                                 activation_62[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_65 (Activation)      (None, 28, 28, 512)  0           add_21[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_66 (Activation)      (None, 28, 28, 128)  0           bn3c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_67 (Activation)      (None, 28, 28, 128)  0           bn3c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_67[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_22 (Add)                    (None, 28, 28, 512)  0           bn3c_branch2c[0][0]              \n",
      "                                                                 activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_68 (Activation)      (None, 28, 28, 512)  0           add_22[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_68[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_69 (Activation)      (None, 28, 28, 128)  0           bn3d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_69[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_70 (Activation)      (None, 28, 28, 128)  0           bn3d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_70[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_23 (Add)                    (None, 28, 28, 512)  0           bn3d_branch2c[0][0]              \n",
      "                                                                 activation_68[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_71 (Activation)      (None, 28, 28, 512)  0           add_23[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2a (Conv2D)         (None, 14, 14, 256)  131328      activation_71[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_72 (Activation)      (None, 14, 14, 256)  0           bn4a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_72[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_73 (Activation)      (None, 14, 14, 256)  0           bn4a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_73[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch1 (Conv2D)          (None, 14, 14, 1024) 525312      activation_71[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch1 (BatchNormalizatio (None, 14, 14, 1024) 4096        res4a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_24 (Add)                    (None, 14, 14, 1024) 0           bn4a_branch2c[0][0]              \n",
      "                                                                 bn4a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_74 (Activation)      (None, 14, 14, 1024) 0           add_24[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_74[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_75 (Activation)      (None, 14, 14, 256)  0           bn4b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_75[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_76 (Activation)      (None, 14, 14, 256)  0           bn4b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_76[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_25 (Add)                    (None, 14, 14, 1024) 0           bn4b_branch2c[0][0]              \n",
      "                                                                 activation_74[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_77 (Activation)      (None, 14, 14, 1024) 0           add_25[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_77[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_78 (Activation)      (None, 14, 14, 256)  0           bn4c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_78[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_79 (Activation)      (None, 14, 14, 256)  0           bn4c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_79[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_26 (Add)                    (None, 14, 14, 1024) 0           bn4c_branch2c[0][0]              \n",
      "                                                                 activation_77[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_80 (Activation)      (None, 14, 14, 1024) 0           add_26[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_80[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_81 (Activation)      (None, 14, 14, 256)  0           bn4d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_81[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_82 (Activation)      (None, 14, 14, 256)  0           bn4d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_82[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_27 (Add)                    (None, 14, 14, 1024) 0           bn4d_branch2c[0][0]              \n",
      "                                                                 activation_80[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_83 (Activation)      (None, 14, 14, 1024) 0           add_27[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_83[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_84 (Activation)      (None, 14, 14, 256)  0           bn4e_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_84[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_85 (Activation)      (None, 14, 14, 256)  0           bn4e_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_85[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4e_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_28 (Add)                    (None, 14, 14, 1024) 0           bn4e_branch2c[0][0]              \n",
      "                                                                 activation_83[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_86 (Activation)      (None, 14, 14, 1024) 0           add_28[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_86[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_87 (Activation)      (None, 14, 14, 256)  0           bn4f_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_87[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_88 (Activation)      (None, 14, 14, 256)  0           bn4f_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_88[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4f_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_29 (Add)                    (None, 14, 14, 1024) 0           bn4f_branch2c[0][0]              \n",
      "                                                                 activation_86[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_89 (Activation)      (None, 14, 14, 1024) 0           add_29[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2a (Conv2D)         (None, 7, 7, 512)    524800      activation_89[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_90 (Activation)      (None, 7, 7, 512)    0           bn5a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_91 (Activation)      (None, 7, 7, 512)    0           bn5a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_91[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch1 (Conv2D)          (None, 7, 7, 2048)   2099200     activation_89[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch1 (BatchNormalizatio (None, 7, 7, 2048)   8192        res5a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_30 (Add)                    (None, 7, 7, 2048)   0           bn5a_branch2c[0][0]              \n",
      "                                                                 bn5a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_92 (Activation)      (None, 7, 7, 2048)   0           add_30[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_92[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_93 (Activation)      (None, 7, 7, 512)    0           bn5b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_93[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_94 (Activation)      (None, 7, 7, 512)    0           bn5b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_94[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_31 (Add)                    (None, 7, 7, 2048)   0           bn5b_branch2c[0][0]              \n",
      "                                                                 activation_92[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_95 (Activation)      (None, 7, 7, 2048)   0           add_31[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_95[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_96 (Activation)      (None, 7, 7, 512)    0           bn5c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_96[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_97 (Activation)      (None, 7, 7, 512)    0           bn5c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_97[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_32 (Add)                    (None, 7, 7, 2048)   0           bn5c_branch2c[0][0]              \n",
      "                                                                 activation_95[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_98 (Activation)      (None, 7, 7, 2048)   0           add_32[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "avg_pool (AveragePooling2D)     (None, 1, 1, 2048)   0           activation_98[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_1 (Glo (None, 2048)         0           avg_pool[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 2048)         0           global_average_pooling2d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 10)           20490       dropout_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 23,608,202\n",
      "Trainable params: 23,555,082\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "resnet50_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Variable *= will be deprecated. Use variable.assign_mul if you want assignment to the variable value or 'x = x * y' if you want a new python Tensor object.\n",
      "Epoch 1/3\n",
      "281/281 [==============================] - 396s 1s/step - loss: 1.9721 - acc: 0.3298 - val_loss: 1.0782 - val_acc: 0.8456\n",
      "Epoch 2/3\n",
      "281/281 [==============================] - 112s 399ms/step - loss: 0.9014 - acc: 0.7723 - val_loss: 0.4271 - val_acc: 0.9395\n",
      "Epoch 3/3\n",
      "281/281 [==============================] - 112s 400ms/step - loss: 0.4267 - acc: 0.9131 - val_loss: 0.2324 - val_acc: 0.9625\n"
     ]
    }
   ],
   "source": [
    "from keras import optimizers\n",
    "\n",
    "sgd = optimizers.SGD(lr=0.0001, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "\n",
    "resnet50_model.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "hist = resnet50_model.fit_generator(resnet50_train_generator, len(resnet50_train_generator), epochs=3,\\\n",
    "                                    validation_data=resnet50_valid_generator, validation_steps=len(resnet50_valid_generator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "281/281 [==============================] - 116s 411ms/step - loss: 0.2468 - acc: 0.9536 - val_loss: 0.1532 - val_acc: 0.9739\n",
      "Epoch 2/5\n",
      "281/281 [==============================] - 111s 396ms/step - loss: 0.1622 - acc: 0.9718 - val_loss: 0.1140 - val_acc: 0.9784\n",
      "Epoch 3/5\n",
      "281/281 [==============================] - 112s 397ms/step - loss: 0.1180 - acc: 0.9780 - val_loss: 0.0909 - val_acc: 0.9804\n",
      "Epoch 4/5\n",
      "281/281 [==============================] - 112s 399ms/step - loss: 0.0906 - acc: 0.9836 - val_loss: 0.0767 - val_acc: 0.9821\n",
      "Epoch 5/5\n",
      "281/281 [==============================] - 110s 393ms/step - loss: 0.0712 - acc: 0.9887 - val_loss: 0.0666 - val_acc: 0.9839\n"
     ]
    }
   ],
   "source": [
    "hist = resnet50_model.fit_generator(resnet50_train_generator, len(resnet50_train_generator), epochs=5,\\\n",
    "                                    validation_data=resnet50_valid_generator, validation_steps=len(resnet50_valid_generator))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "由于时间关系我就不继续往下训练了，可以看到我们已经将“训练集loss高居不下”的问题解决了，也就是之前列出来的两个问题中的第一个。看起来一切都很完美，完美得我们都已经忽略存在的第二个问题，因为从上面的训练结果不太明显（其实也能看出来，因为每次epoch之后，训练loss都明显高于验证loss），如果你执意认为没问题，那好，让我们将该模型在测试集上运行，然后将运行结果提交kaggle就知道了。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def get_test_result(model_obj, test_generator, model_name=\"default\"):\n",
    "    pred_test = model_obj.predict_generator(test_generator, len(test_generator))\n",
    "    pred_test = np.array(pred_test)\n",
    "    pred_test = pred_test.clip(min=0.005, max=0.995)\n",
    "    \n",
    "    df = pd.read_csv(\"sample_submission.csv\")\n",
    "\n",
    "    for i, fname in enumerate(test_generator.filenames):\n",
    "        df.loc[df[\"img\"] == fname] = [fname] + list(pred_test[i])\n",
    "    \n",
    "    df.to_csv('%s.csv' % (model_name), index=None)\n",
    "    print ('test result file %s.csv generated!' % (model_name))\n",
    "    df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test result file resnet-50.csv generated!\n"
     ]
    }
   ],
   "source": [
    "get_test_result(resnet50_model, resnet50_test_generator, model_name=\"resnet-50\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "不出所料，提交到kaggle之后，loss是惊人的2.3。现在就来分析一下哪里有问题吧！从之前的训练过程可以看出，每一次验证集的loss都是要低于测试集的loss，这很不正常。说明我们验证集直接或者间接的过拟合了。为什么会过拟合呢？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
